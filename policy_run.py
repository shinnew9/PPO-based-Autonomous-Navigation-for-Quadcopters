# Revised some code here since the original code is based on unstable assumption that the image file is always ready
import os
import gym
import yaml
import numpy as np

if not hasattr(np, "bool8"):
    np.bool8 = np.bool_

from gym import spaces
from stable_baselines3 import PPO
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv, VecEnvWrapper



# 0) Resetì—
class ResetCompat(gym.Wrapper):
    def reset(self, *args, **kwargs):
        # AirSimDroneEnvëŠ” ì¸ì ì—†ëŠ” resetë§Œ ì§€ì›í•˜ë‹ˆê¹Œ ì‹¹ ë¬´ì‹œ
        obs = self.env.reset()   # ë„ˆí¬ AirSim envëŠ” obsë§Œ ë¦¬í„´í•¨
        return obs, {}           # SB3ê°€ ê¸°ëŒ€í•˜ëŠ” (obs, info) í˜•íƒœë¡œ ë§ì¶°ì¤Œ


class StepCompat(gym.Wrapper):
    def step(self, action):
        out = self.env.step(action)
        # ì—£ë‚ ì‹ì´ë©´ ê¸¸ì´ê°€ 4ì¼ ê±°ë‹¤
        if len(out) == 4:
            obs, reward, done, info = out
            terminated = bool(done)
            truncated = False
            return obs, reward, terminated, truncated, info
        # ì´ë¯¸ ìƒˆì‹ì´ë©´ ê·¸ëŒ€ë¡œ
        return out

# 1) changes the channel automatically (N, H, W, C) -> (N, C, H, W) í•˜ê³ , ê³µê°„ë„ ë°”ê¿”ì£¼ëŠ” Wrapper
class ChannelLastToFirst(VecEnvWrapper):
    def __init__(self, venv):
        super().__init__(venv)
        # ì›ë˜ ê³µê°„: (50, 50, 3)
        old_space = venv.observation_space
        assert isinstance(old_space, spaces.Box)
        h, w, c = old_space.shape
        # SB3 modelì´ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ê³µê°„ì„ ë°”ê¿”ì¤€ë‹¤: (C, H, W)
        self.observation_space = spaces.Box(
            low=0,
            high=255,
            shape=(c, h, w),
            dtype=old_space.dtype,
        )

    def reset(self):
        obs = self.venv.reset()   # (n_env, H, W, C)
        return self._transpose(obs)

    def step_wait(self):
        obs, rewards, dones, infos = self.venv.step_wait()
        return self._transpose(obs), rewards, dones, infos

    def _transpose(self, obs):
        # (n_env, H, W, C) -> (n_env, C, H, W)
        return np.transpose(obs, (0, 3, 1, 2))


# 2) Get train environment configs
with open('scripts/config.yml', 'r') as f:
    cfg = yaml.safe_load(f)
train_cfg = cfg.get("TrainEnv", {})


# 3) env ë§Œë“œëŠ” í•¨ìˆ˜ (DummyVecEnvê°€ ìš”êµ¬í•˜ëŠ” í˜•íƒœ)
def make_env():
    # ì—¬ê¸° idëŠ” ë ˆí¬ê°€ ë“±ë¡í•´ë‘” ê±° ê·¸ëŒ€ë¡œ ì”€
    env = gym.make(
        "scripts:test-env-v0", 
        ip_address="127.0.0.1",  # Make sure TrainEnv.exe is always turned on when runnign this py file
        image_shape=(50, 50, 3),   # config.ymlì´ë‘ ë§ì¶°ë‘ 
        env_config=train_cfg
    )
    env = ResetCompat(env)
    env = StepCompat(env)
    env = Monitor(env)
    return env


env = DummyVecEnv([make_env])
# Model expects (3, 50, 50), transpose to appropriate size
env = ChannelLastToFirst(env)

print("ğŸ‘€ final observation_space:", env.observation_space)


# 4) Model Load
model_path = os.path.join("saved_policy", "ppo_navigation_policy")
# ì´ ë ˆí¬ëŠ” ë³´í†µ ppo_navigation_policy.zip ìœ¼ë¡œ ì €ì¥ë¼ ìˆì„ê±°ë¼ì„œ ë‘˜ ë‹¤ ì²´í¬
if os.path.exists(model_path + ".zip"):
    model_path = model_path + ".zip"
elif not os.path.exists(model_path):
    raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”: {model_path}(.zip)")


# 5) Covering SB3 model
custom_objects = {
    "lr_schedule": lambda _: 3e-4,  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ì„ ê·¸ëƒ¥ ìƒìˆ˜ë¡œ   
    "clip_range": 0.2,              # í´ë¦¬í•‘ë„ ìƒìˆ˜ë¡œ
}
model = PPO.load(model_path, env=None, custom_objects=custom_objects)


# Run the trained policy
obs = env.reset()
for _ in range(1000):
    action, _ = model.predict(obs, deterministic=True)
    obs, reward, done, info = env.step(action)
    if done.any():
        obs = env.reset()
